{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see more data/movie-actor/make_casting_graph.py\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "from pprint import pprint \n",
    "\n",
    "\n",
    "# pre defined casting weight graph\n",
    "with open('data/movie-actor/casting_graph.pkl', 'rb') as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "# create idx to actor name function\n",
    "with open('data/movie-actor/actors.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    docs = [line[:-1].split('\\t') for line in f]\n",
    "    # English name if exist else Korean name\n",
    "    _idx2actor = {doc[0]:(doc[2] if doc[2] else doc[1]) for doc in docs}\n",
    "\n",
    "# create idx to movie name function\n",
    "def append_year_countries(year, countries):\n",
    "    if year and countries:\n",
    "        return ' ({}, {})'.format(year, countries)\n",
    "    elif year:\n",
    "        return ' ({})'.format(year)\n",
    "    elif countries:\n",
    "        return ' ({})'.format(countries)\n",
    "    return ''\n",
    "\n",
    "with open('data/movie-actor/movies.csv', encoding='utf-8') as f:\n",
    "    next(f)\n",
    "    docs = [line[:-1].split('\\t') for line in f]\n",
    "    _idx2movie = {doc[0]:'{}{}'.format(doc[1], append_year_countries(doc[4], doc[5])) for doc in docs if len(docs)}\n",
    "    _idx2year = {doc[0]:(int(doc[4]) if doc[4] else 0) for doc in docs if len(docs)}\n",
    "\n",
    "# create idx to num comments\n",
    "with open('data/movie-actor/num_comments.txt', encoding='utf-8') as f:\n",
    "    docs = [line[:-1].split('\\t') for line in f]\n",
    "    _idx2numcomments = {movie_idx:int(num) for movie_idx, num in docs}\n",
    "\n",
    "idx2movie = lambda idx: _idx2movie.get(idx, 'Unknown')\n",
    "idx2year = lambda idx: _idx2year.get(idx, 0)\n",
    "idx2actor = lambda idx: _idx2actor.get(idx, 'Unknown')\n",
    "idx2numcomments = lambda idx: _idx2numcomments.get(idx,0)\n",
    "\n",
    "\n",
    "# Transform one-way to bidirected\n",
    "sys.path.append('data/movie-actor/')\n",
    "from make_casting_graph import oneway_to_bidirected_graph\n",
    "\n",
    "g = oneway_to_bidirected_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with Python dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie 22682', 'actor 7995', 'actor 4009', 'movie 25882', 'actor 154441']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(g.keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# making bias\n",
    "bias = {node:(idx2numcomments(node.split()[1]) if node[0] == 'm' else 0) for node in g}\n",
    "_sum = sum(bias.values())\n",
    "bias = {node:b / _sum for node, b in bias.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration = 1, diff = 0.9735227399459792, sum = 0.9999999999998657\n",
      "Iteration = 2, diff = 0.7586092188109216, sum = 0.9999999999989707\n",
      "Iteration = 3, diff = 0.612136395804903, sum = 1.0000000000001668\n",
      "Iteration = 4, diff = 0.5041426449280965, sum = 0.9999999999996744\n",
      "Iteration = 5, diff = 0.4205911434661837, sum = 1.0000000000000329\n",
      "Iteration = 6, diff = 0.35282857845349685, sum = 0.9999999999997901\n",
      "Iteration = 7, diff = 0.29719895865328017, sum = 1.0000000000000615\n",
      "Iteration = 8, diff = 0.25081504214011324, sum = 1.0000000000002625\n",
      "Iteration = 9, diff = 0.2120067786422557, sum = 0.9999999999999264\n",
      "Iteration = 10, diff = 0.17937385549497817, sum = 0.999999999999767\n",
      "Iteration = 11, diff = 0.15187850974117678, sum = 1.0000000000001241\n",
      "Iteration = 12, diff = 0.1286725921232049, sum = 1.000000000000105\n",
      "Iteration = 13, diff = 0.1090574423391369, sum = 1.0000000000001614\n",
      "Iteration = 14, diff = 0.09246572410873297, sum = 1.000000000000169\n",
      "Iteration = 15, diff = 0.07842074920691962, sum = 0.9999999999999504\n",
      "Iteration = 16, diff = 0.06652319068670189, sum = 0.9999999999996392\n",
      "Iteration = 17, diff = 0.056442575142103255, sum = 0.9999999999998407\n",
      "Iteration = 18, diff = 0.04789569903743898, sum = 0.9999999999998039\n",
      "Iteration = 19, diff = 0.040650477675364095, sum = 0.9999999999998772\n",
      "Iteration = 20, diff = 0.03450412893311997, sum = 1.0000000000002278\n",
      "Iteration = 21, diff = 0.02929172837277342, sum = 0.9999999999998991\n",
      "Iteration = 22, diff = 0.024867993273519, sum = 0.9999999999997299\n",
      "Iteration = 23, diff = 0.021115125673952836, sum = 1.0000000000000546\n",
      "Iteration = 24, diff = 0.017928953217522945, sum = 0.9999999999996925\n",
      "Iteration = 25, diff = 0.01522536066877409, sum = 1.000000000000079\n",
      "Iteration = 26, diff = 0.012929539401768895, sum = 0.999999999999928\n",
      "Iteration = 27, diff = 0.010980990361079983, sum = 0.9999999999999283\n",
      "Iteration = 28, diff = 0.009326150181234918, sum = 0.9999999999998334\n",
      "Iteration = 29, diff = 0.007921357893600102, sum = 1.0000000000000673\n",
      "Iteration = 30, diff = 0.006728220624778119, sum = 1.000000000000381\n",
      "computation time : 42.505 sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pagerank import pagerank\n",
    "\n",
    "t = time.time()\n",
    "rank = pagerank(g,\n",
    "                bias=bias,\n",
    "                df=0.15,\n",
    "                max_iter=30,\n",
    "                converge_error=0.001,\n",
    "                verbose=1)\n",
    "\n",
    "t = time.time() - t\n",
    "print('computation time : %.3f sec' % t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether famous movie has high rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인천상륙작전 (2016, 한국)\n",
      "연평해전 (2015, 한국)\n",
      "국가대표 (2009, 한국)\n",
      "설국열차 (2013, 한국)\n",
      "어벤져스: 에이지 오브 울트론 (2015, 미국)\n",
      "국제시장 (2014, 한국)\n",
      "겨울왕국 (2014, 미국)\n",
      "암살 (2015, 한국)\n",
      "7번방의 선물 (2013, 한국)\n",
      "캡틴 아메리카: 시빌 워 (2016, 미국)\n",
      "곡성(哭聲) (2016, 한국)\n",
      "귀향 (2016, 한국)\n",
      "26년 (2012, 한국)\n",
      "인터스텔라 (2014, 미국 영국)\n",
      "세 얼간이 (2011, 인도)\n",
      "부산행 (2016, 한국)\n",
      "아가씨 (2016, 한국)\n",
      "레미제라블 (2012, 영국)\n",
      "밀정 (2016, 한국)\n",
      "럭키 (2016, 한국)\n",
      "디 워 (2007, 한국)\n",
      "판도라 (2016, 한국)\n",
      "미스터 고 (2013, 한국)\n",
      "다세포 소녀 (2006, 한국)\n",
      "해운대 (2009, 한국)\n",
      "님아, 그 강을 건너지 마오 (2014, 한국)\n",
      "광해, 왕이 된 남자 (2012, 한국)\n",
      "수상한 그녀 (2014, 한국)\n",
      "트랜스포머: 사라진 시대 (2014, 미국)\n",
      "킹스맨 : 시크릿 에이전트 (2015, 미국 영국)\n",
      "괴물 (2006, 한국)\n",
      "아수라 (2016, 한국)\n",
      "역린 (2014, 한국)\n",
      "포화 속으로 (2010, 한국)\n",
      "어거스트 러쉬 (2007, 미국)\n",
      "비긴 어게인 (2014, 미국)\n",
      "검은 사제들 (2015, 한국)\n",
      "아바타 (2009, 미국)\n",
      "말할 수 없는 비밀 (2008, 대만)\n",
      "베테랑 (2015, 한국)\n",
      "덕혜옹주 (2016, 한국)\n",
      "감기 (2013, 한국)\n",
      "타워 (2012, 한국)\n",
      "라스트 갓파더 (2010, 한국 미국)\n",
      "늑대소년 (2012, 한국)\n",
      "왕의 남자 (2005, 한국)\n",
      "그래비티 (2013, 미국 영국)\n",
      "영웅: 샐러멘더의 비밀 (2013, 한국 미국 러시아 연방)\n",
      "라디오 스타 (2006, 한국)\n",
      "과속스캔들 (2008, 한국)\n",
      "신비한 동물사전 (2016, 미국 영국)\n",
      "쎄시봉 (2015, 한국)\n",
      "미녀는 괴로워 (2006, 한국)\n",
      "퍼시픽 림 (2013, 미국)\n",
      "다이빙벨 (2014, 한국)\n",
      "클레멘타인 (2004, 한국 미국)\n",
      "인턴 (2015, 미국)\n",
      "인사이드 아웃 (2015, 미국)\n",
      "신세계 (2013, 한국)\n",
      "세븐 데이즈 (2007, 한국)\n",
      "천안함 프로젝트 (2013, 한국)\n",
      "엑스맨: 데이즈 오브 퓨처 패스트 (2014, 미국)\n",
      "매드맥스: 분노의 도로 (2015, 오스트레일리아)\n",
      "아저씨 (2010, 한국)\n",
      "월드워Z (2013, 미국)\n",
      "연가시 (2012, 한국)\n",
      "검사외전 (2016, 한국)\n",
      "배트맨 대 슈퍼맨: 저스티스의 시작 (2016, 미국)\n",
      "엑스맨: 아포칼립스 (2016, 미국)\n",
      "해리 포터와 죽음의 성물 - 2부 (2011, 미국 영국)\n",
      "데드풀 (2016, 미국)\n",
      "숨바꼭질 (2013, 한국)\n",
      "2012 (2009, 미국 캐나다)\n",
      "킹콩을 들다 (2009, 한국)\n",
      "7급 공무원 (2009, 한국)\n",
      "미스 페레그린과 이상한 아이들의 집 (2016, 미국)\n",
      "시간을 달리는 소녀 (2007, 일본)\n",
      "신의 한 수 (2014, 한국)\n",
      "레버넌트: 죽음에서 돌아온 자 (2016, 미국)\n",
      "탐정 : 더 비기닝 (2015, 한국)\n",
      "트랜스포머 3 (2011, 미국)\n",
      "군도:민란의 시대 (2014, 한국)\n",
      "남자사용설명서 (2013, 한국)\n",
      "수어사이드 스쿼드 (2016, 미국 캐나다)\n",
      "강남 1970 (2015, 한국)\n",
      "완득이 (2011, 한국)\n",
      "손님 (2015, 한국)\n",
      "인생은 아름다워 (1999, 이탈리아)\n",
      "해적: 바다로 간 산적 (2014, 한국)\n",
      "루시 (2014, 프랑스 미국)\n",
      "화려한 휴가 (2007, 한국)\n",
      "쌍화점 (2008, 한국)\n",
      "엣지 오브 투모로우 (2014, 미국)\n",
      "돈 크라이 마미 (2012, 한국)\n",
      "다크 나이트 라이즈 (2012, 미국 영국)\n",
      "감시자들 (2013, 한국)\n",
      "센과 치히로의 행방불명 (2002, 일본)\n",
      "친절한 금자씨 (2005, 한국)\n",
      "제이슨 본 (2016, 미국)\n",
      "터널 (2016, 한국)\n"
     ]
    }
   ],
   "source": [
    "movie_rank = {node:rank for node, rank in rank.items() if node[0] == 'm'}\n",
    "actor_rank = {node:rank for node, rank in rank.items() if node[0] == 'a'}\n",
    "\n",
    "for movie, _ in sorted(movie_rank.items(), key=lambda x:-x[1])[:100]:\n",
    "    movie_idx = movie.split()[1]\n",
    "    print(idx2movie(movie_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265607,)\n",
      "(265607, 265607)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "# node index\n",
    "nodes = set(g.keys())\n",
    "idx2node = list(sorted(nodes))\n",
    "node2idx = {node:idx for idx, node in enumerate(idx2node)}\n",
    "\n",
    "# bias\n",
    "bias = np.asarray([b for node, b in sorted(bias.items(), key=lambda tp:node2idx[tp[0]])])\n",
    "print(bias.shape)\n",
    "\n",
    "# transform g to sparse matrix\n",
    "rows = []\n",
    "cols = []\n",
    "data = []\n",
    "\n",
    "for from_node, to_dict in g.items():\n",
    "    from_idx = node2idx[from_node]\n",
    "    for to_node, weight in to_dict.items():\n",
    "        to_idx = node2idx[to_node]\n",
    "        rows.append(from_idx)\n",
    "        cols.append(to_idx)\n",
    "        data.append(weight)\n",
    "\n",
    "A = csc_matrix((data, (rows, cols)))\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train PageRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1 : diff = 0.281436840863022\n",
      "iter 2 : diff = 0.3970505378527365\n",
      "iter 3 : diff = 0.17598404082440902\n",
      "iter 4 : diff = 0.14807658516192676\n",
      "iter 5 : diff = 0.09962315062320268\n",
      "iter 6 : diff = 0.0765602968138843\n",
      "iter 7 : diff = 0.058114626092355424\n",
      "iter 8 : diff = 0.042949603335787775\n",
      "iter 9 : diff = 0.03410703651803252\n",
      "iter 10 : diff = 0.024663500399523496\n",
      "iter 11 : diff = 0.020053770053409213\n",
      "iter 12 : diff = 0.014331538003882077\n",
      "iter 13 : diff = 0.011801592719125686\n",
      "iter 14 : diff = 0.008385166921666137\n",
      "iter 15 : diff = 0.0069544954062276815\n",
      "iter 16 : diff = 0.004925645467125705\n",
      "iter 17 : diff = 0.004106103285551124\n",
      "iter 18 : diff = 0.002901720075500885\n",
      "iter 19 : diff = 0.002430137343265774\n",
      "iter 20 : diff = 0.0017143036073690432\n",
      "iter 21 : diff = 0.001442295384774437\n",
      "iter 22 : diff = 0.0010158693712554695\n",
      "iter 23 : diff = 0.0008586564597530771\n",
      "iter 24 : diff = 0.0006037068986667392\n",
      "iter 25 : diff = 0.0005127185595059035\n",
      "iter 26 : diff = 0.00035977812698531186\n",
      "iter 27 : diff = 0.0003070013906231215\n",
      "iter 28 : diff = 0.0002150577888443411\n",
      "iter 29 : diff = 0.000184323520834479\n",
      "iter 30 : diff = 0.00012896538325120755\n",
      "0.2700066566467285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "max_iter = 30\n",
    "df = 0.85\n",
    "\n",
    "ir = 1 / A.shape[0]\n",
    "rank = np.asarray([ir] * A.shape[0])\n",
    "\n",
    "for n_iter in range(1, max_iter + 1):\n",
    "    rank_new = A.dot(rank) # call scipy.sparse safe_sparse_dot()\n",
    "    rank_new = normalize(rank_new.reshape(1, -1), norm='l1').reshape(-1)\n",
    "    rank_new = df * rank_new + (1 - df) * bias    \n",
    "    diff = abs(rank - rank_new).sum()\n",
    "    rank = rank_new\n",
    "    print('iter {} : diff = {}'.format(n_iter, diff))\n",
    "\n",
    "t = time.time() - t\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether famous movie has high rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26년 (2012, 한국)\n",
      "부산행 (2016, 한국)\n",
      "디 워 (2007, 한국)\n",
      "곡성(哭聲) (2016, 한국)\n",
      "7번방의 선물 (2013, 한국)\n",
      "인터스텔라 (2014, 미국 영국)\n",
      "인천상륙작전 (2016, 한국)\n",
      "국제시장 (2014, 한국)\n",
      "괴물 (2006, 한국)\n",
      "국가대표 (2009, 한국)\n",
      "암살 (2015, 한국)\n",
      "베테랑 (2015, 한국)\n",
      "아바타 (2009, 미국)\n",
      "연평해전 (2015, 한국)\n",
      "설국열차 (2013, 한국)\n",
      "말할 수 없는 비밀 (2008, 대만)\n",
      "겨울왕국 (2014, 미국)\n",
      "왕의 남자 (2005, 한국)\n",
      "캡틴 아메리카: 시빌 워 (2016, 미국)\n",
      "님아, 그 강을 건너지 마오 (2014, 한국)\n",
      "늑대소년 (2012, 한국)\n",
      "귀향 (2016, 한국)\n",
      "과속스캔들 (2008, 한국)\n",
      "어벤져스: 에이지 오브 울트론 (2015, 미국)\n",
      "세 얼간이 (2011, 인도)\n",
      "다세포 소녀 (2006, 한국)\n",
      "검사외전 (2016, 한국)\n",
      "아저씨 (2010, 한국)\n",
      "군도:민란의 시대 (2014, 한국)\n",
      "광해, 왕이 된 남자 (2012, 한국)\n",
      "해적: 바다로 간 산적 (2014, 한국)\n",
      "해운대 (2009, 한국)\n",
      "터널 (2016, 한국)\n",
      "화려한 휴가 (2007, 한국)\n",
      "아가씨 (2016, 한국)\n",
      "럭키 (2016, 한국)\n",
      "다크 나이트 라이즈 (2012, 미국 영국)\n",
      "다이빙벨 (2014, 한국)\n",
      "덕혜옹주 (2016, 한국)\n",
      "아수라 (2016, 한국)\n",
      "다크 나이트 (2008, 미국)\n",
      "밀정 (2016, 한국)\n",
      "인셉션 (2010, 미국 영국)\n",
      "포화 속으로 (2010, 한국)\n",
      "전우치 (2009, 한국)\n",
      "검은 사제들 (2015, 한국)\n",
      "히말라야 (2015, 한국)\n",
      "트랜스포머 (2007, 미국)\n",
      "7광구 (2011, 한국)\n",
      "좋은 놈, 나쁜 놈, 이상한 놈 (2008, 한국)\n"
     ]
    }
   ],
   "source": [
    "rank_ = {idx2node[idx]:value for idx, value in enumerate(rank)}\n",
    "movierank = {node:value for node, value in rank_.items() if 'movie' in node}\n",
    "actorrank = {node:value for node, value in rank_.items() if 'actor' in node}\n",
    "\n",
    "for movie, value in sorted(movierank.items(), key=lambda x:-x[1])[:50]:\n",
    "    movie_idx = movie.split()[1]\n",
    "    print(idx2movie(movie_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
